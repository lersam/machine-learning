{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea86f777",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=aircAruvnKk\n",
    "https://www.youtube.com/watch?v=IHZwWFHWa-w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a16381",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058b7990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from www.openml.org\n",
    "mnist_path = r'D:/workspace/machine-learning/number-recognition/local_data/mnist.pickle'\n",
    "with open(mnist_path, 'rb') as f:\n",
    "        y = pickle.load(f)\n",
    "        X = pickle.load(f)\n",
    "print(f\"Dataset shapes: X={X.shape}, y={y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58893c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cc640c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74237f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 250\n",
    "# Display an image (optional)\n",
    "# Reshape the 784-pixel flat array into a 28x28 image\n",
    "image_data = X[index].reshape(28, 28)\n",
    "plt.imshow(image_data, cmap='gray')\n",
    "plt.title(f\"Label: {y[index]}\")\n",
    "plt.show()\n",
    "\n",
    "# X contains the image data (as a 2D array of samples x pixels)\n",
    "# y contains the labels (the actual number for each image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a688f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumberRecognition(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(784, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 10),\n",
    "            torch.nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c8414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognition_model = NumberRecognition().to(device)\n",
    "recognition_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c83a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data (stratify preserves label proportions)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Ensure labels are integers\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long, device=device)\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.long, device=device)\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "test_dataset = TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Now `train_dataset`, `test_dataset`, `train_loader`, and `test_loader` are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d3d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstration purposes\n",
    "x, y = next(iter(train_loader))\n",
    "y_pred = recognition_model(x)\n",
    "print(y_pred.argmax(dim=1))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0157fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(recognition_model.parameters(), lr=0.001)\n",
    "epoch_losses = []\n",
    "for epoch in range(100):  # number of epochs\n",
    "    recognition_model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = recognition_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e3866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(epoch_losses, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4771875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model accuracy evaluation\n",
    "recognition_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = recognition_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b62fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model accuracy evaluation\n",
    "recognition_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in train_loader:\n",
    "        outputs = recognition_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "accuracy = correct / total\n",
    "print(f\"Train Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc3d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction helpers and examples\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def predict_index(idx):\n",
    "    \"\"\"Predict and show a single test image by index.\"\"\"\n",
    "    recognition_model.eval()\n",
    "    img = X_test[idx]\n",
    "    inp = torch.tensor(img, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        out = recognition_model(inp)\n",
    "        probs = torch.exp(out)  # model uses LogSoftmax\n",
    "        top_prob, top_idx = probs.topk(1, dim=1)\n",
    "    pred = int(top_idx[0,0].item())\n",
    "    prob = float(top_prob[0,0].item())\n",
    "    plt.imshow(img.reshape(28,28), cmap='gray')\n",
    "    plt.title(f'Pred: {pred} ({prob:.2f}), True: {int(y_test[idx])}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_random_predictions(n=9):\n",
    "    \"\"\"Display n random predictions from the test set in a grid.\"\"\"\n",
    "    recognition_model.eval()\n",
    "    n = min(n, len(X_test))\n",
    "    inds = np.random.choice(len(X_test), n, replace=False)\n",
    "    cols = int(np.ceil(np.sqrt(n)))\n",
    "    rows = int(np.ceil(n / cols))\n",
    "    plt.figure(figsize=(cols*2, rows*2))\n",
    "    for i, idx in enumerate(inds):\n",
    "        ax = plt.subplot(rows, cols, i+1)\n",
    "        img = X_test[idx].reshape(28,28)\n",
    "        inp = torch.tensor(X_test[idx], dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            out = recognition_model(inp)\n",
    "            probs = torch.exp(out)\n",
    "            pred = int(probs.argmax(dim=1).item())\n",
    "            prob = float(probs[0, pred].item())\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f'{pred} ({prob:.2f})\\nTrue: {int(y_test[idx])}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Examples - call these to visualize predictions:\n",
    "predict_index(0)\n",
    "show_random_predictions(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d815070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all images from X with labels, paginated, 10 images per row\n",
    "# WARNING: still a lot of output for full dataset; use smaller page_size if desired\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_cols = 10  # 10 images per line\n",
    "n_rows = 10  # rows per page (adjust to change page size)\n",
    "page_size = n_cols * n_rows\n",
    "total = len(X)\n",
    "for start in range(0, total, page_size):\n",
    "    end = min(start + page_size, total)\n",
    "    imgs = X[start:end]\n",
    "    count = len(imgs)\n",
    "    rows = math.ceil(count / n_cols)\n",
    "    plt.figure(figsize=(n_cols * 1.6, rows * 1.6))\n",
    "    for i in range(count):\n",
    "        ax = plt.subplot(rows, n_cols, i + 1)\n",
    "        plt.imshow(imgs[i].reshape(28, 28), cmap='gray')\n",
    "        plt.title(f'Idx {start + i}  Label: {y[start + i]}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
