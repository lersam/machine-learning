{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef5baea323f52f3",
   "metadata": {},
   "source": [
    "# Load Individual Household Electric Power Consumption\n",
    "https://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c45ea2e5ca19833",
   "metadata": {},
   "source": [
    "## Readme\n",
    "- https://medium.com/@ottaviocalzone/an-intuitive-explanation-of-lstm-a035eb6ab42c\n",
    "- https://www.youtube.com/watch?v=b61DPVFX03I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d38f009d4e48ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from support import EnergyConsumptionDataset, EnergyConsumptionModule, build_loaders, demo_model_shapes, \\\n",
    "    plot_convergence, train_and_evaluate, plot_predictions_grid, plot_mse_horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf9c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"local_data/cache\"\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33ca755",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e197fa8ca27b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T12:36:06.697549Z",
     "start_time": "2026-01-12T12:36:05.586098Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data = EnergyConsumptionDataset(history_samples=24 * 14, horizon_samples=24 * 3, scale=True, train_fraction=0.9)\n",
    "print(\"data length: \", len(all_data))\n",
    "print(\"number of channels: \", all_data.number_of_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f2a7704a6bc484",
   "metadata": {},
   "source": [
    "# Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d7a019f81ea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.data_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed199c2ce5698f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T12:36:06.968635Z",
     "start_time": "2026-01-12T12:36:06.922870Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, train_loader, test_loader = build_loaders(all_data, train_fraction=0.9, batch_size_train=200, batch_size_eval=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936775b17a0a0014",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T12:36:07.114704Z",
     "start_time": "2026-01-12T12:36:07.094587Z"
    }
   },
   "outputs": [],
   "source": [
    "model = EnergyConsumptionModule(input_dim=all_data.number_of_channels, output_dim=all_data.horizon_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8371b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_model_shapes(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4f7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file_name = os.path.join(data_folder, \"ERAdmission-CNN-LSTM-Fusion.checkpoint.pt\")\n",
    "model, progress_log, test_accuracy, test_loader = train_and_evaluate(model, train_dataset, test_dataset, device=device, n_epochs=1, batch_size=200, lr=1e-3, checkpoint_file_name=checkpoint_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec85a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence(progress_log, test_accuracy)\n",
    "plot_predictions_grid(model, test_loader, device=device, n=6)\n",
    "plot_mse_horizon(model, test_loader, all_data.horizon_samples, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f278c0bb",
   "metadata": {},
   "source": [
    "# Prediction Examples\n",
    "Below are small, focused examples showing how to run predictions with the trained `model` and `test_loader`.\n",
    "Each code block is a single, logical step: prepare batch, run prediction, compute simple metrics, and plot results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c2a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Prepare a small batch for inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_all, y_all = next(iter(test_loader))\n",
    "    # move inputs to device if available\n",
    "    X_all = X_all.to(device) if 'device' in globals() else X_all\n",
    "    n_samples = min(6, X_all.shape[0])\n",
    "    X_sample = X_all[:n_samples]\n",
    "    y_true = y_all[:n_samples].cpu()\n",
    "    # reduce to primary channel if necessary: (batch, channels, horizon) -> (batch, horizon)\n",
    "    if y_true.ndim == 3:\n",
    "        y_true = y_true[:, 0, :]\n",
    "    print('Prepared', n_samples, 'samples ->', 'X_sample', X_sample.shape, 'y_true', y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c2a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Run prediction on the small batch and prepare results for plotting\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_sample)\n",
    "    # model may return shape (batch, channels, horizon) or (batch, horizon)\n",
    "    if y_pred.ndim == 3:\n",
    "        y_pred = y_pred[:, 0, :]\n",
    "    y_pred = y_pred.cpu()\n",
    "print('y_pred shape', y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a16f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Compute simple MSE metrics on the small batch\n",
    "mse_per_sample = ((y_pred - y_true) ** 2).mean(dim=1)\n",
    "print('MSE per sample:', mse_per_sample.numpy())\n",
    "print('Mean MSE (batch):', float(mse_per_sample.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c42a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Plot actual vs predicted for the small batch (easy visual check)\n",
    "import matplotlib.pyplot as plt\n",
    "rows, cols = 2, 3\n",
    "plt.figure(figsize=(14, 8))\n",
    "for i in range(y_pred.shape[0]):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.plot(y_true[i], label='Actual', marker='o', markersize=3)\n",
    "    plt.plot(y_pred[i], label='Predicted', marker='x', markersize=3, alpha=0.8)\n",
    "    plt.xlabel('Horizon step')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.title(f'Sample {i} â€” MSE: {mse_per_sample[i]:0.4f}')\n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
